/*
 * Tachyon API
 *
 * Tachyon Platform REST API
 *
 * The version of the OpenAPI document: 0.48.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// ClientToolDefinition : User-defined tool definition sent via the API request.  Uses JSON Schema format compatible with OpenAI/Anthropic function calling. Tool definitions are passed to the LLM alongside server built-in tools so the model can decide when to invoke them.  # Example  ```json {   \"name\": \"query_database\",   \"description\": \"Run a read-only SQL query\",   \"parameters\": {     \"type\": \"object\",     \"properties\": {       \"sql\": { \"type\": \"string\" }     },     \"required\": [\"sql\"]   },   \"fire_and_forget\": false } ```
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct ClientToolDefinition {
    /// Human-readable description shown to the LLM so it can decide when to call this tool.
    #[serde(rename = "description")]
    pub description: String,
    /// When `true`, the server dispatches the tool call to the client and immediately returns a success message to the LLM without waiting for a result submission. The client still receives the `tool_call_pending` SSE event but does not need to call the tool-result endpoint. Useful for notifications, webhooks, logging, and other side-effect-only operations.
    #[serde(rename = "fire_and_forget", skip_serializing_if = "Option::is_none")]
    pub fire_and_forget: Option<bool>,
    /// Unique tool name. Must not collide with server built-in tools (e.g. `read_file`, `execute_command`, `search_files`). Use descriptive, snake_case names.
    #[serde(rename = "name")]
    pub name: String,
    #[serde(rename = "parameters", deserialize_with = "Option::deserialize")]
    pub parameters: Option<serde_json::Value>,
}

impl ClientToolDefinition {
    /// User-defined tool definition sent via the API request.  Uses JSON Schema format compatible with OpenAI/Anthropic function calling. Tool definitions are passed to the LLM alongside server built-in tools so the model can decide when to invoke them.  # Example  ```json {   \"name\": \"query_database\",   \"description\": \"Run a read-only SQL query\",   \"parameters\": {     \"type\": \"object\",     \"properties\": {       \"sql\": { \"type\": \"string\" }     },     \"required\": [\"sql\"]   },   \"fire_and_forget\": false } ```
    pub fn new(description: String, name: String, parameters: Option<serde_json::Value>) -> ClientToolDefinition {
        ClientToolDefinition {
            description,
            fire_and_forget: None,
            name,
            parameters,
        }
    }
}

